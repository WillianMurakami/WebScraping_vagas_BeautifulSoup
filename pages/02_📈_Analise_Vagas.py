import streamlit as st
import pandas as pd
import spacy
from collections import Counter
import plotly.express as px
from datetime import datetime
import numpy as np

# Carregar o modelo de idioma portuguÃªs do spaCy
nlp = spacy.load("pt_core_news_sm")

# Stopwords especÃ­ficas para cada categoria
COMMON_STOPWORDS = {
    "domÃ­nio", "experiÃªncia", "conhecimento", "sÃ³lido", "avanÃ§ado", "familiaridade", "tÃ©cnico", "desejÃ¡vel",
    "analÃ­tico", "proficiente", "proficiÃªncia", "detalhado", "essencial", "importante", "capacidade", "nÃ­vel",
    "habilidade", "excelente", "fundamental", "competÃªncia", "Ã¡rea", "Ã¡reas", "vida", "saÃºde", "trabalho", "empresa",
    "vale", "completo", "superior", "ambiente", "colaboradores", "colaborador", "atividades", "anos", "dia", "garantindo",
    "serÃ¡", "notas", "auxÃ­lio", "refeiÃ§Ã£o", "busca", "vaga", "alimentaÃ§Ã£o", "gente", "creche", "benefÃ­cios", "trabalhar",
    "dias", "visando", "uso", "utilizaÃ§Ã£o", "soluÃ§Ã£o", "implementaÃ§Ã£o", "integraÃ§Ã£o", "desenvolvimento", "serviÃ§o",
    "sistema", "tecnologia", "plataforma", "software", "aplicativo", "programa", "cresol", "time", "ciÃªncias", "estamos", "garantir", "garantindo",
    "profissional", "aÃ§Ãµes", "aÃ§Ã£o", "oportunidades", "oportunidade", "responsÃ¡vel",
}

def normalize_terms(text, stopwords_set):
    """Normaliza os termos extraindo tokens sem stopwords."""
    doc = nlp(text.lower())
    tokens = [token.text for token in doc if token.is_alpha and not token.is_stop and token.text not in stopwords_set]
    return Counter(tokens)

def categorize_terms(df):
    """Extrai hard skills, soft skills e ferramentas dos anÃºncios de vagas."""
    hard_skills = Counter()
    soft_skills = Counter()
    tools = Counter()

    if 'description' in df.columns:
        description_text = " ".join(df['description'].dropna())
    else:
        description_text = ""

    # Processamento distinto para cada categoria
    hard_skills.update(normalize_terms(description_text, COMMON_STOPWORDS))
    soft_skills.update(normalize_terms(description_text, COMMON_STOPWORDS))
    tools.update(normalize_terms(description_text, COMMON_STOPWORDS))

    # Limitar a exibiÃ§Ã£o a 45 palavras mais frequentes
    hard_skills = dict(hard_skills.most_common(45))
    soft_skills = dict(soft_skills.most_common(45))
    tools = dict(tools.most_common(45))

    return hard_skills, soft_skills, tools

def calculate_days_between(dates1, dates2):
    """Calcula o nÃºmero de dias entre duas listas de datas, preservando o comprimento original."""
    days = [(d2 - d1).days if pd.notnull(d1) and pd.notnull(d2) else np.nan for d1, d2 in zip(dates1, dates2)]
    return days

# Verificar se os dados do scraping estÃ£o presentes
if 'job_data' not in st.session_state or st.session_state.job_data.empty:
    st.warning("Nenhum dado de vaga encontrado. Por favor, faÃ§a a busca de vagas antes de acessar a anÃ¡lise.")
else:
    df_vagas = st.session_state.job_data

    # Ajustar os dados de data
    df_vagas['Data de PublicaÃ§Ã£o'] = pd.to_datetime(df_vagas['publishedDate'].str.split('T').str[0], errors='coerce')
    if 'applicationDeadline' in df_vagas.columns:
        df_vagas['Data de Candidatura'] = pd.to_datetime(df_vagas['applicationDeadline'].str.split('T').str[0], errors='coerce')

    st.title("AnÃ¡lise de Vagas ğŸ“ˆ")
    st.markdown("""Aqui temos as principais informaÃ§Ãµes das vagas. 
Neste painel vocÃª encontrarÃ¡ informaÃ§Ãµes para facilitar sua anÃ¡lise e compreensÃ£o sobre a Ã¡rea pesquisada!""")

    # Linha 1: CartÃµes de MÃ©tricas com nova ordem e proporÃ§Ã£o
    col1, col2, col3, col4 = st.columns([0.2, 0.2, 0.2, 0.4])

    with col1:
        total_vagas = len(df_vagas)
        st.metric(label="Total de Vagas", value=total_vagas)

    with col2:
        data_min = df_vagas['Data de PublicaÃ§Ã£o'].min().date() if not df_vagas['Data de PublicaÃ§Ã£o'].isnull().all() else None
        data_max = df_vagas['Data de PublicaÃ§Ã£o'].max().date() if not df_vagas['Data de PublicaÃ§Ã£o'].isnull().all() else None
        total_dias = (data_max - data_min).days if data_max and data_min else 1
        st.metric(label="Total de Dias Observados", value=total_dias)

    with col3:
        # Tempo mÃ©dio de fechamento das vagas
        if 'Data de Candidatura' in df_vagas.columns:
            df_vagas['Tempo Fechamento'] = calculate_days_between(
                df_vagas['Data de PublicaÃ§Ã£o'], df_vagas['Data de Candidatura']
            )
            tempo_medio_fechamento = df_vagas['Tempo Fechamento'].mean() if not df_vagas['Tempo Fechamento'].empty else 0
            st.metric(label="Tempo MÃ©dio de Fechamento", value=f"{tempo_medio_fechamento:.2f} dias")

    with col4:
        if data_min and data_min != data_max:
            selected_date = st.slider("Controle de Tempo", min_value=data_min, max_value=data_max, value=(data_min, data_max))
        else:
            st.write(f"A Ãºnica data disponÃ­vel Ã© {data_min}.")
            selected_date = (data_min, data_max)

    # Converter datas selecionadas para datetime64[ns] para compatibilidade com pandas
    selected_start = pd.to_datetime(selected_date[0])
    selected_end = pd.to_datetime(selected_date[1])

    df_filtered = df_vagas[(df_vagas['Data de PublicaÃ§Ã£o'] >= selected_start) & (df_vagas['Data de PublicaÃ§Ã£o'] <= selected_end)]

    # GrÃ¡fico de Linhas - Vagas por Data
    if not df_filtered['Data de PublicaÃ§Ã£o'].isnull().all():
        publicacao_counts = df_filtered['Data de PublicaÃ§Ã£o'].value_counts().sort_index().reset_index()
        publicacao_counts.columns = ['Data', 'NÃºmero de Vagas']
        fig_publicacao = px.line(publicacao_counts, x='Data', y='NÃºmero de Vagas', labels={'Data': 'Data', 'NÃºmero de Vagas': 'NÃºmero de Vagas'}, title='Vagas por Data de PublicaÃ§Ã£o')
        st.plotly_chart(fig_publicacao)

    # Linha 2: GrÃ¡ficos de Modalidade de ContrataÃ§Ã£o e Sunburst
    col5, col6 = st.columns([0.5, 0.5])

    with col5:
        if 'type' in df_filtered.columns:
            df_filtered['Modalidade Traduzida'] = df_filtered['type'].apply(lambda x: x.split('_')[-1]).map({
                'effective': 'Efetivo',
                'legal': 'Pessoa JurÃ­dica',
                'temporary': 'TemporÃ¡rio'
            })
            modalidade_counts = df_filtered['Modalidade Traduzida'].value_counts()
            pie_fig = px.pie(modalidade_counts, values=modalidade_counts, names=modalidade_counts.index, title='Modalidade de ContrataÃ§Ã£o')
            st.plotly_chart(pie_fig)

    with col6:
        sunburst_data = df_filtered.copy()
        sunburst_data['Estado'] = sunburst_data.apply(lambda row: 'Remoto' if row['isRemoteWork'] else row['state'], axis=1)
        sunburst_data['Cidade'] = sunburst_data.apply(lambda row: 'Remoto' if row['isRemoteWork'] else row['city'], axis=1)
        
        # Conte o nÃºmero de vagas por Estado e Cidade
        sunburst_count = sunburst_data.groupby(['Estado', 'Cidade']).size().reset_index(name='NÃºmero de Vagas')

        sunburst_fig = px.sunburst(
            sunburst_count,
            path=['Estado', 'Cidade'],
            values='NÃºmero de Vagas',
            title="DistribuiÃ§Ã£o de Vagas por Estado e Cidade"
        )
        st.plotly_chart(sunburst_fig)

    # Linha 3: GrÃ¡fico de Vagas por Empresa
    empresa_counts = df_filtered['careerPageName'].value_counts().nlargest(15)
    demais_empresas = df_filtered['careerPageName'].value_counts().iloc[15:].sum()
    top_empresas = pd.concat([empresa_counts, pd.Series({'Demais': demais_empresas})])

    empresa_fig = px.bar(top_empresas.sort_values(ascending=False), y=top_empresas.index, x=top_empresas.values, orientation='h', 
                         title='Top 15 Empresas por NÃºmero de Vagas')
    empresa_fig.update_layout(yaxis_title='Empresas', xaxis_title='NÃºmero de Vagas', 
                              plot_bgcolor='rgba(0,0,0,0)', yaxis=dict(showgrid=True), xaxis=dict(showgrid=True))
    st.plotly_chart(empresa_fig)

    # Modalidade do Trabalho como GrÃ¡fico de Pizza
    if 'Modalidade de Trabalho' in df_filtered.columns:
        work_type_counts = df_filtered['Modalidade de Trabalho'].value_counts()
        pie_fig = px.pie(work_type_counts, values=work_type_counts, names=work_type_counts.index, title='Modalidade de Trabalho')
        st.plotly_chart(pie_fig)

    # AnÃ¡lise de Texto: ExtraÃ§Ã£o e VisualizaÃ§Ã£o de Habilidades e Ferramentas
    st.header("AnÃ¡lise de Habilidades e Ferramentas")
    st.markdown("""
    A anÃ¡lise feita pela IA, utilizando a biblioteca spaCy, aponta que as principais caracterÃ­sticas necessÃ¡rias para essas vagas sÃ£o:
    \n\n*(Esse grÃ¡fico pode levar mais tempo para ser gerado devido Ã  anÃ¡lise detalhada realizada pela IA.)*
    """)

    hard_skills, soft_skills, tools = categorize_terms(df_filtered)

    # Treemap para Ferramentas e Habilidades
    combined_skills_tools = Counter(hard_skills) + Counter(soft_skills) + Counter(tools)
    if combined_skills_tools:
        treemap_data = pd.DataFrame(combined_skills_tools.items(), columns=['CaracterÃ­stica', 'FrequÃªncia'])
        treemap_data = treemap_data.sort_values(by='FrequÃªncia', ascending=False).head(45)
        fig_treemap = px.treemap(treemap_data, path=['CaracterÃ­stica'], values='FrequÃªncia', title="Principais CaracterÃ­sticas Requeridas")
        fig_treemap.update_traces(tiling=dict(pad=1))
        st.plotly_chart(fig_treemap)

# ConfiguraÃ§Ã£o da barra lateral
st.sidebar.markdown(
    """
    Projeto desenvolvido por [Willian Murakami](https://www.linkedin.com/in/willian-murakami/)
    Para mais projetos, [clique aqui](https://github.com/WillianMurakami).
    """
)
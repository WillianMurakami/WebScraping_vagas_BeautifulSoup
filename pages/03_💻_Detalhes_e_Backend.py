import streamlit as st
import requests
import pandas as pd
import plotly.express as px

# ConfiguraÃ§Ã£o da barra lateral
st.sidebar.markdown(
    """
    Projeto desenvolvido por [Willian Murakami](https://www.linkedin.com/in/willian-murakami/).
    Para mais projetos, [clique aqui](https://share.streamlit.io/user/willianmurakami).
    """
)

# TÃ­tulo e IntroduÃ§Ã£o
st.title("ğŸ”§ VisÃ£o TÃ©cnica do Dashboard de Vagas")
st.markdown("""
Bem-vindo Ã  visÃ£o tÃ©cnica desse projeto de Webscraping e anÃ¡lise visual das vagas! Nesta pÃ¡gina, a ideia Ã© explicar melhor sobre as ferramentas utilizadas, os mÃ©todos desenvolvidos e o fluxo de trabalho aplicado para tornar o projeto funcional e eficiente. 
Se vocÃª deseja entender como as diferentes partes do projeto se integram, estÃ¡ no lugar certo!
""")

# Ferramentas e Tecnologias
st.header("ğŸ— Ferramentas e Tecnologias Utilizadas")
st.markdown("""
O projeto faz uso de uma stack tecnolÃ³gica moderna e robusta, que inclui:
- **ğŸ Python**: Linguagem base devido Ã  sua versatilidade e ecossistema rico em bibliotecas de anÃ¡lise e visualizaÃ§Ã£o de dados.
- **ğŸ“¡ Requests**: Biblioteca para realizar requisiÃ§Ãµes HTTP, usada para consumir dados da API Gupy.
- **ğŸ—ƒ pandas**: Biblioteca essencial para manipulaÃ§Ã£o e anÃ¡lise dos dados.
- **ğŸ“Š Plotly**: Ferramenta de visualizaÃ§Ã£o interativa para grÃ¡ficos de alta qualidade.
- **ğŸ”„ Streamlit**: Framework para criaÃ§Ã£o de dashboards e aplicativos web interativos para o usuÃ¡rio final de forma Ã¡gil e intuitiva.
- **â˜ï¸ Streamlit Cloud**: Para deploy direto e compartilhamento da aplicaÃ§Ã£o de forma online e colaborativa.
""")

# Fluxo Geral do Projeto
st.header("ğŸ“‹ Fluxo Geral do Projeto")
st.markdown("""
O fluxo de trabalho do projeto pode ser resumido em 3 etapas principais:

1. **Coleta de Dados**:
    - Os dados de vagas de emprego sÃ£o raspados (coletados) a partir da API do portal Gupy usando a biblioteca `requests`.
    - SÃ£o realizadas requisiÃ§Ãµes paginadas para garantir que grandes volumes de dados sejam coletados.

2. **Processamento de Dados**:
    - Os dados brutos retornados pela API sÃ£o processados com o `pandas` para limpeza, padronizaÃ§Ã£o e organizaÃ§Ã£o.
    - MÃ©todos sÃ£o aplicados para lidar com informaÃ§Ãµes como datas, palavras-chave e cÃ¡lculo de mÃ©tricas.

3. **VisualizaÃ§Ã£o Interativa**:
    - Utilizamos `Streamlit` e `Plotly` para criar grÃ¡ficos interativos que permitem ao usuÃ¡rio explorar as informaÃ§Ãµes.
    - O dashboard facilita a anÃ¡lise de tendÃªncias, comparaÃ§Ã£o de empresas e visualizaÃ§Ã£o de caracterÃ­sticas chave.
""")

# ExplicaÃ§Ãµes de CÃ³digo e MÃ©todos
st.header("ğŸ“œ ExplicaÃ§Ãµes de CÃ³digo e MÃ©todos")

st.subheader("1ï¸âƒ£ Coleta de Dados")
st.code("""
def fetch_jobs_from_api(job_name, max_results=1000):
    jobs = []
    offset = 0
    limit = 10

    while len(jobs) < max_results:
        formatted_job_name = job_name.replace(' ', '%20')
        api_url = f"https://portal.api.gupy.io/api/v1/jobs?jobName={formatted_job_name}&offset={offset}&limit={limit}"
        headers = {'User-Agent': 'Mozilla/5.0'}
        
        response = requests.get(api_url, headers=headers)
        if response.status_code == 200:
            data = response.json()
            batch_jobs = data.get('data', [])
            
            if not batch_jobs:
                break

            jobs.extend(batch_jobs)
            offset += limit
        else:
            st.error(f"Erro ao acessar API: {response.status_code}")
            break

    return pd.DataFrame(jobs[:max_results])
""", language='python')
st.markdown("""
Esse mÃ©todo utiliza a biblioteca `requests` para realizar chamadas Ã  API do Gupy e obter dados de vagas em lotes (paginados). Os principais pontos aqui sÃ£o:
- **ParÃ¢metros de controle**: `offset` e `limit` sÃ£o usados para obter dados em pequenos blocos e evitar sobrecarga.
- **Tratamento de erros**: Verificamos o cÃ³digo de resposta da API (`status_code`) e paramos a execuÃ§Ã£o caso algo dÃª errado.
- **TransformaÃ§Ã£o em DataFrame**: No final, os dados sÃ£o estruturados com o `pandas` para fÃ¡cil manipulaÃ§Ã£o.
""")

st.subheader("2ï¸âƒ£ Processamento e Limpeza de Dados")
st.code("""
def process_job_data(df):
    df['Data de PublicaÃ§Ã£o'] = pd.to_datetime(df['publishedDate'].str.split('T').str[0], errors='coerce')
    if 'applicationDeadline' in df.columns:
        df['Data de Candidatura'] = pd.to_datetime(df['applicationDeadline'].str.split('T').str[0], errors='coerce')
    if 'Data de Candidatura' in df.columns:
        df['Tempo de Fechamento'] = (df['Data de Candidatura'] - df['Data de PublicaÃ§Ã£o']).dt.days

    return df.dropna(subset=['Data de PublicaÃ§Ã£o'])
""", language='python')
st.markdown("""
Este mÃ©todo ilustra como os dados brutos retornados pela API sÃ£o organizados e limpos:
- **ConversÃ£o de Datas**: Os campos de data sÃ£o convertidos para o formato `datetime` para cÃ¡lculos e filtragem.
- **CÃ¡lculo de MÃ©tricas**: Calculamos o tempo mÃ©dio de fechamento de vagas subtraindo a data de publicaÃ§Ã£o da data limite.
- **RemoÃ§Ã£o de Nulos**: Garantimos que apenas registros vÃ¡lidos sejam mantidos no DataFrame.
""")

st.subheader("3ï¸âƒ£ VisualizaÃ§Ã£o de Dados")
st.code("""
fig_publicacao = px.line(publicacao_counts, x='Data', y='NÃºmero de Vagas', title='Vagas por Data de PublicaÃ§Ã£o')
st.plotly_chart(fig_publicacao)
""", language='python')
st.markdown("""
Este Ã© um exemplo de visualizaÃ§Ã£o criada com o Plotly para exibir o nÃºmero de vagas publicadas por dia:
- **GrÃ¡fico de Linhas**: Escolhemos este formato para mostrar tendÃªncias ao longo do tempo.
- **Interatividade**: Com o Plotly, o grÃ¡fico permite zoom e visualizaÃ§Ã£o dinÃ¢mica dos dados.
""")

st.subheader("4ï¸âƒ£ ExtraÃ§Ã£o de Palavras Relevantes")
st.code("""
def extract_relevant_terms(text, stopwords):
    words = text.lower().split()
    keywords = [word.strip(",.") for word in words if word not in stopwords and len(word) > 3]
    return Counter(keywords)
""", language='python')
st.markdown("""
Esta funÃ§Ã£o analisa as descriÃ§Ãµes das vagas e extrai palavras-chave relevantes:
- **RemoÃ§Ã£o de Stopwords**: Stopwords comuns como "vaga", "empresa", "trabalho" sÃ£o ignoradas.
- **Contagem de FrequÃªncia**: Usamos `collections.Counter` para contar a ocorrÃªncia de termos significativos.
""")

# ConclusÃ£o
st.header("ğŸ“Œ ConclusÃ£o")
st.markdown("""
O dashboard desenvolvido demonstra como unir Python, APIs e ferramentas de visualizaÃ§Ã£o pode simplificar a anÃ¡lise de dados complexos. 
Com abordagens modulares e bibliotecas poderosas como `pandas` e `Plotly`, Ã© possÃ­vel criar soluÃ§Ãµes interativas e eficazes para explorar informaÃ§Ãµes em tempo real.
""")
